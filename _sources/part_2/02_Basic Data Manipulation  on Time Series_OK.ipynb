{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "negative-import",
   "metadata": {},
   "source": [
    "# Chapter 2: Basic Data Manipulation  on Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-throw",
   "metadata": {},
   "source": [
    "Working with time series data can be intimidating at first. The time series values are not the only information you have to consider. The `timestamps` also contain information, especially about the relationship between the values. In contrast to common data types, timestamps have a few unique characteristics. While they look like a string at first glance, they also have numerical aspects. This section will present essential techniques for effectively managing time series data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-listening",
   "metadata": {},
   "source": [
    "##  How to Deal with Datetime Format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-watson",
   "metadata": {},
   "source": [
    "The essential part of time series data is the time component. The interval at which the variable or the phenomenon is observed or recorded. In Pandas, they take the form of **timestamps**. If these timestamps are in\n",
    "Datetime format, you can apply various manipulations, which we will discuss in this\n",
    "section. If not, you will have to convert it into the convenient format to unlock its various functionalities. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-clinic",
   "metadata": {},
   "source": [
    "## Reading Datetime Format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-norwegian",
   "metadata": {},
   "source": [
    "By default, when reading from a CSV file that contains time series, unless carefully coded before hand, `Pandas` reads timestamp columns as `strings` into a DataFrame, instead of `datetime64[ns]` data type. \n",
    "Let's practice the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-kingston",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-formula",
   "metadata": {},
   "source": [
    ">#### <font color=#800080>Example:</font> <a class=\"anchor\" id=\"Task-1\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-analyst",
   "metadata": {},
   "source": [
    "Good air quality can have a direct impact on property valuations. For real estate agencies, it is vital to their businesses to study the quality of the air in a certain geographical area before building settlements. The reason is that, \n",
    "\n",
    "* Areas with better air quality can lead to higher property values.\n",
    "\n",
    "\n",
    "* Areas with better air quality reduces the risks of respiratory ailments, allergies, and other health problems as Homebuyers and renters often prioritize their health and the health of their families.\n",
    "\n",
    "\n",
    "* Areas with better air quality tend to have lower maintenance costs. Polluted air can lead to faster wear and tear on building materials, increased cleaning needs, and even damage to property.\n",
    "\n",
    "\n",
    "Alain-realty, a real estate agency located in Kinshasa, Democratic Republic of Congo, plans to build luxious apartments in response to the improved lifestyle of the Congolese people resulting from the exploitation of coltan mines used in electric cars. They have engaged a team of Engineers from P.L. Global Consulting to assess the air quality in Bagata, an outskirt in Kinshasa. They have installed sensors capable of measuring the Ambiant Temperature, relative and absolute humidity from March 3rd, 2004, to April 4th, 2005, at 30-minute intervals. The resulting data is stored in a `csv` file provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-truth",
   "metadata": {},
   "outputs": [],
   "source": [
    "airqual_data =  pd.read_csv('data/Air_Quality_bagata.csv')\n",
    "airqual_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-packaging",
   "metadata": {},
   "source": [
    "Let's explore the data types of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-adult",
   "metadata": {},
   "outputs": [],
   "source": [
    "airqual_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-speech",
   "metadata": {},
   "source": [
    "Though the date column contains date instances, its data type is still regarded as an `object`. Hence , we need to convert into `datetime` object to use all the date related functionalities. This is done by using the `pd.to_datetime()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-discovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "airqual_data['Date']= pd.to_datetime(airqual_data['Date'])\n",
    "airqual_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-baking",
   "metadata": {},
   "source": [
    ">#### <font color=#800080>Q:</font> <a class=\"anchor\" id=\"Task-1\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-craps",
   "metadata": {},
   "source": [
    "\n",
    "Let's get  a visual of the series  by running the code below to see the evolution of temperature.\n",
    "\n",
    "1. Report on what you observe?\n",
    "2. If you have spotted any anomaly, what do you suggest we do about it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-termination",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,5))\n",
    "plt.plot(airqual_data['Temp'])\n",
    "plt.ylabel('temperature')\n",
    "plt.xlabel('time component')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-roberts",
   "metadata": {},
   "source": [
    "### From Datetime to date and time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-concord",
   "metadata": {},
   "source": [
    "When you have a date and a timestamp, you can decompose them into their\n",
    "components. As shown below, we are breaking the `Date` column into actual `dates` and `time column` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-mixer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting date and time\n",
    "airqual_data[\"dates\"] = airqual_data[\"Date\"].dt.date\n",
    "airqual_data[\"times\"] = airqual_data[\"Date\"].dt.time\n",
    "airqual_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-management",
   "metadata": {},
   "source": [
    "### Exploring the date "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-clear",
   "metadata": {},
   "source": [
    "The `date` itself could also be decomposed it into smaller components, which includes year, month and day as shown below. Further down the line, this could in turn unlock information related to **weekly observations, monthly insights or quaterly observations**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-malta",
   "metadata": {},
   "outputs": [],
   "source": [
    "airqual_data[\"year\"] = airqual_data[\"Date\"].dt.year\n",
    "\n",
    "airqual_data[\"month\"] = airqual_data[\"Date\"].dt.month\n",
    "\n",
    "airqual_data[\"day\"] = airqual_data[\"Date\"].dt.day\n",
    "\n",
    "airqual_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-spirit",
   "metadata": {},
   "outputs": [],
   "source": [
    "airqual_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-brooklyn",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.date_range(\"2021-10-03 18:00:00\",\"2022-04-04 14:00:00\", freq='30T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-jurisdiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.date_range(\"2021/01/01\", \"2021/01/10\" , freq='D')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-architecture",
   "metadata": {},
   "source": [
    "As you could observe, separate columns have been allocated to `year`, `month` and `day`, which makes it easier to query the data effectively. For instance, see this concrete example. \n",
    "\n",
    "The first part of the rainy season in the Democratic Republic of Congo usually runs from October to December. Farmers usually termed it as `mpisoli ya banzambe` (tears of gods). Let's call it **\"mpisoli\"** for the sake of this exercise. Here is how the operations performed above could be useful.\n",
    "\n",
    "The Enigneers from the P.L. Global Constulting might want to know:\n",
    "\n",
    "* The maximum air temperature throughout the whole Mpisoli duration,\n",
    "* The average air temperature of each month of that period.\n",
    "* The highest absolute humidity for each month of that spell.\n",
    "\n",
    "Let's extract those information from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-honor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "round(np.random.uniform(14.5, 30.5),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-actor",
   "metadata": {},
   "outputs": [],
   "source": [
    "airqual_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-motor",
   "metadata": {},
   "outputs": [],
   "source": [
    "airqual_data['month'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-argentina",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpisoli_data = airqual_data[airqual_data['month'].isin([10,11,12])]\n",
    "mpisoli_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respective-armor",
   "metadata": {},
   "source": [
    "**#1.** The maximum air temperature throughout the whole Mbula duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpisoli_data['Temp'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-surprise",
   "metadata": {},
   "source": [
    "**#2.** The average air temperature of each month of that period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-booth",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpisoli_data.groupby('month')['Temp'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-hello",
   "metadata": {},
   "source": [
    "**#3.** The highest absolute humidity for each month of that spell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpisoli_data.groupby('month')['Abs_Hum'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-painting",
   "metadata": {},
   "source": [
    "One could also choose to focus on specific month and get any summary related to that month. See below for instance, the minimum temperature in November 2004."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-digit",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpisoli_data[ (mpisoli_data['year'] == 2004) &  (mpisoli_data['month'] == 11)]['Temp'].min() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-success",
   "metadata": {},
   "source": [
    "Strange right?!! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-sender",
   "metadata": {},
   "source": [
    "Another interesting insight is that one could also group data in terms of weeks prior to extracting information from it. For the dataframe to respond to the query effectively, we should set the date column as an index of the dataframe using the `set_index` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-generic",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpisoli_data.set_index('Date', inplace=True)\n",
    "mpisoli_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-package",
   "metadata": {},
   "source": [
    "If we are interested in the **weekly averages of Temperature or/and absolute humidity** during mpisoli, one could groupby the data by weeks using the frequency parameter, and pass in a list of variables we need the aggregates for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_grouping_mpisoli = mpisoli_data.groupby(pd.Grouper(freq='W'))\n",
    "mpisoli_data[['Temp', 'Abs_Hum']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-ivory",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_data_mpisoli = weekly_grouping_mpisoli[['Temp', 'Abs_Hum']].mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-gothic",
   "metadata": {},
   "source": [
    "This can lead to answering questions like: \n",
    "* What is the week with the lowest temperature?\n",
    "* Does temperature tend to increase  on a average on weekly basis or\n",
    "\n",
    "Or also lead to the generation of weekly summaries as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "weeks = ['week_'+ str(i+1) for i in range(14)]\n",
    "plt.figure(figsize=(18,6))\n",
    "plt.plot(weeks, weekly_data_mpisoli['Temp'])\n",
    "plt.xlabel('weeks')\n",
    "plt.ylabel('avg temperature')\n",
    "plt.title('Weekly temperature during Bagata')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-transmission",
   "metadata": {},
   "source": [
    "### Assembling Multiple Columns to a Datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-percentage",
   "metadata": {},
   "source": [
    "Sometimes, data could be collected in form of separate columns of date components like  year, month,\n",
    "and day. We could also assemble that and create a date column from those components still, using the `.to_datetime()` method. Here, we create a `date_2` column to work that out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-march",
   "metadata": {},
   "outputs": [],
   "source": [
    "airqual_data[\"date_2\"] = pd.to_datetime(airqual_data[[\"year\", \"month\", \"day\"]])\n",
    "airqual_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-injection",
   "metadata": {},
   "source": [
    ">#### <font color=#800080>Task 3:</font> <a class=\"anchor\" id=\"Task-1\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-entertainment",
   "metadata": {},
   "source": [
    "Monitoring air quality and understanding the data can guide many industries in making informed decisions, adopting cleaner technologies, ensuring public health, and contributing to the overall betterment of the environment. For instance, in Agriculture, \n",
    "\n",
    "1. Good air quality is necessary for Crop Health, as farmers, could monitor pollutants that can impact crop health and yield.\n",
    "\n",
    "2. Good air quality could also guide Farming Practices: Selecting crop varieties resistant to certain pollutants or altering farming practices to mitigate the effects of poor air quality.\n",
    "\n",
    "As a Data Analyst, you are on a working collaboration with JVE Mali, An environmental agency in Mali. The goal is to provide farmers with insights related the Air quality, as this could help them decide whihc plant to grow, when to visit their farms without fearing any respiratory diseases due to air pollution. With the materials acquired from the Government Project titled \"Encourger le Paysan Malien (EPM)\" which goal is to encourage farming practices among the youth, You have measured different related to polluants in Sikasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-uruguay",
   "metadata": {},
   "source": [
    "As a Data Analyst, you collaborate with JVE Mali, an environmental agency in Mali. The aim is to provide farmers with insights on Air quality, enabling them to choose suitable crops and also to plan farm regular visits to their plots without respiratory disease concerns. Using materials acquired from the Government Project named \"Encourager le Paysan Malien (EPM)\" that aims to promote farming practices among young entrepreneurs, JVE  have rolled out a data collection campaign across Southern Mali, starting with the City of Sikasso throughout the Year 2022. Some of the polluants' concentration that were measured include\n",
    "\n",
    "* PM2.5 (Fine particulate matter)\n",
    "* PM10 (Coarse particulate matter)\n",
    "* O₃ (Ozone)\n",
    "* CO (Carbon monoxide)\n",
    "* SO₂ (Sulfur dioxide)\n",
    "* NO₂ (Nitrogen dioxide)\n",
    "\n",
    "The resulting information is encapsulated in the csv file called `sikasso_aq.csv`.\n",
    "\n",
    "\n",
    "1. Load the dataset and tell us what you observe.\n",
    "\n",
    "2.  Produce a dataframe that contains the montly averages of the Coarse particulate matter (PM10). Make sure you replace the month number by the actual month name in your final result. You may use the hint below.\n",
    "\n",
    "`data_frame['month_name'] = pd.to_datetime(data_frame['month'], format='%m').dt.month_name().str.slice()`\n",
    "\n",
    "\n",
    "3. Determine monthly average dynamics of Coarse particulate matter (PM10) and identify the months with lowest and highest average value. Return the results in form of a graph. Save those values somewhere as they represent the $C_{low}$ and $C_{high}$ for that polluant. \n",
    "\n",
    "4. For every other polluant, repeat the Question 2. and 3. above. To avoid re-writing codes from scratch, you might want to customize some functions that perform the Q2 and Q3. \n",
    "\n",
    "\n",
    "5. Compute the Quaterly average for each of the polluants and report the lowest and largest value for each of the polluants."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
